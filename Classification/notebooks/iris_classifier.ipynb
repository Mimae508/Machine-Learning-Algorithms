{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Iris Flower Classification Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "This specific dataset seperates flowers into 3 different classes of species:\n",
    "1. Setosa\n",
    "2. Versicolor\n",
    "3. Virginica\n",
    "\n",
    "The information about each flower is the following:\n",
    "1. sepal length\n",
    "2. sepal width\n",
    "3. petal length\n",
    "4. petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')\n",
    "#y_train = dftrain.pop('Species')\n",
    "#y_eval = dfeval.pop('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To view the first 5 rows/entries of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>120</th>\n",
       "      <th>4</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   120    4  setosa  versicolor  virginica\n",
       "0  6.4  2.8     5.6         2.2          2\n",
       "1  5.0  2.3     3.3         1.0          1\n",
       "2  4.9  2.5     4.5         1.7          2\n",
       "3  4.9  3.1     1.5         0.1          0\n",
       "4  5.7  3.8     1.7         0.3          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() # the species column is now gone\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape  # we have 120 entires with 4 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an input function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Intern02\\\\AppData\\\\Local\\\\Temp\\\\tmpab0jzbw8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Evaluate and Predict :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training :O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt-11000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11000...\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11000...\n",
      "INFO:tensorflow:loss = 0.19264224, step = 11000\n",
      "INFO:tensorflow:global_step/sec: 460.079\n",
      "INFO:tensorflow:loss = 0.19054821, step = 11100 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.698\n",
      "INFO:tensorflow:loss = 0.19022533, step = 11200 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.012\n",
      "INFO:tensorflow:loss = 0.19205713, step = 11300 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.569\n",
      "INFO:tensorflow:loss = 0.19521332, step = 11400 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.532\n",
      "INFO:tensorflow:loss = 0.19321688, step = 11500 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.106\n",
      "INFO:tensorflow:loss = 0.1817298, step = 11600 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.508\n",
      "INFO:tensorflow:loss = 0.17881542, step = 11700 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.621\n",
      "INFO:tensorflow:loss = 0.1878747, step = 11800 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.743\n",
      "INFO:tensorflow:loss = 0.18284735, step = 11900 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.678\n",
      "INFO:tensorflow:loss = 0.17743826, step = 12000 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.344\n",
      "INFO:tensorflow:loss = 0.18841174, step = 12100 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.809\n",
      "INFO:tensorflow:loss = 0.18119922, step = 12200 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.098\n",
      "INFO:tensorflow:loss = 0.18169904, step = 12300 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.208\n",
      "INFO:tensorflow:loss = 0.1862036, step = 12400 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.096\n",
      "INFO:tensorflow:loss = 0.1738633, step = 12500 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.426\n",
      "INFO:tensorflow:loss = 0.17366984, step = 12600 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.987\n",
      "INFO:tensorflow:loss = 0.18246996, step = 12700 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.252\n",
      "INFO:tensorflow:loss = 0.1724538, step = 12800 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.012\n",
      "INFO:tensorflow:loss = 0.18715131, step = 12900 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.116\n",
      "INFO:tensorflow:loss = 0.16853863, step = 13000 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.91\n",
      "INFO:tensorflow:loss = 0.17168675, step = 13100 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.43\n",
      "INFO:tensorflow:loss = 0.16957565, step = 13200 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.778\n",
      "INFO:tensorflow:loss = 0.15738656, step = 13300 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.263\n",
      "INFO:tensorflow:loss = 0.17124337, step = 13400 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.258\n",
      "INFO:tensorflow:loss = 0.1775378, step = 13500 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.873\n",
      "INFO:tensorflow:loss = 0.15621969, step = 13600 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.63\n",
      "INFO:tensorflow:loss = 0.16740873, step = 13700 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.193\n",
      "INFO:tensorflow:loss = 0.16671512, step = 13800 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.688\n",
      "INFO:tensorflow:loss = 0.18106236, step = 13900 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.181\n",
      "INFO:tensorflow:loss = 0.16881476, step = 14000 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.234\n",
      "INFO:tensorflow:loss = 0.16717863, step = 14100 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.451\n",
      "INFO:tensorflow:loss = 0.16259056, step = 14200 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.464\n",
      "INFO:tensorflow:loss = 0.15925252, step = 14300 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.865\n",
      "INFO:tensorflow:loss = 0.16087905, step = 14400 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.09\n",
      "INFO:tensorflow:loss = 0.16338226, step = 14500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.301\n",
      "INFO:tensorflow:loss = 0.16104014, step = 14600 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.927\n",
      "INFO:tensorflow:loss = 0.1605213, step = 14700 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.152\n",
      "INFO:tensorflow:loss = 0.15307862, step = 14800 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.502\n",
      "INFO:tensorflow:loss = 0.15714186, step = 14900 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.002\n",
      "INFO:tensorflow:loss = 0.15437427, step = 15000 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.708\n",
      "INFO:tensorflow:loss = 0.14229637, step = 15100 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.619\n",
      "INFO:tensorflow:loss = 0.15306608, step = 15200 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.298\n",
      "INFO:tensorflow:loss = 0.15302473, step = 15300 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.867\n",
      "INFO:tensorflow:loss = 0.14851387, step = 15400 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.663\n",
      "INFO:tensorflow:loss = 0.15326765, step = 15500 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.425\n",
      "INFO:tensorflow:loss = 0.14554082, step = 15600 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.633\n",
      "INFO:tensorflow:loss = 0.15728156, step = 15700 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.22\n",
      "INFO:tensorflow:loss = 0.14444965, step = 15800 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.69\n",
      "INFO:tensorflow:loss = 0.14936092, step = 15900 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.773\n",
      "INFO:tensorflow:loss = 0.15177347, step = 16000 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.026\n",
      "INFO:tensorflow:loss = 0.14774969, step = 16100 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.04\n",
      "INFO:tensorflow:loss = 0.1572804, step = 16200 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.49\n",
      "INFO:tensorflow:loss = 0.15295783, step = 16300 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.724\n",
      "INFO:tensorflow:loss = 0.14213392, step = 16400 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.382\n",
      "INFO:tensorflow:loss = 0.15241808, step = 16500 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.597\n",
      "INFO:tensorflow:loss = 0.13932039, step = 16600 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.272\n",
      "INFO:tensorflow:loss = 0.13998464, step = 16700 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.463\n",
      "INFO:tensorflow:loss = 0.1439043, step = 16800 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.507\n",
      "INFO:tensorflow:loss = 0.13492799, step = 16900 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.52\n",
      "INFO:tensorflow:loss = 0.13973366, step = 17000 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.493\n",
      "INFO:tensorflow:loss = 0.14110538, step = 17100 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.087\n",
      "INFO:tensorflow:loss = 0.14088291, step = 17200 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.448\n",
      "INFO:tensorflow:loss = 0.13648741, step = 17300 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.725\n",
      "INFO:tensorflow:loss = 0.14166924, step = 17400 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.264\n",
      "INFO:tensorflow:loss = 0.14139256, step = 17500 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.628\n",
      "INFO:tensorflow:loss = 0.13555433, step = 17600 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.209\n",
      "INFO:tensorflow:loss = 0.13003254, step = 17700 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.279\n",
      "INFO:tensorflow:loss = 0.14120999, step = 17800 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.38\n",
      "INFO:tensorflow:loss = 0.1425643, step = 17900 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.099\n",
      "INFO:tensorflow:loss = 0.135506, step = 18000 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.763\n",
      "INFO:tensorflow:loss = 0.13696852, step = 18100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.262\n",
      "INFO:tensorflow:loss = 0.1310372, step = 18200 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.515\n",
      "INFO:tensorflow:loss = 0.12948973, step = 18300 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.884\n",
      "INFO:tensorflow:loss = 0.13386652, step = 18400 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.625\n",
      "INFO:tensorflow:loss = 0.13500677, step = 18500 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.652\n",
      "INFO:tensorflow:loss = 0.12507948, step = 18600 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.516\n",
      "INFO:tensorflow:loss = 0.12822911, step = 18700 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.831\n",
      "INFO:tensorflow:loss = 0.13208458, step = 18800 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.788\n",
      "INFO:tensorflow:loss = 0.14424026, step = 18900 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.275\n",
      "INFO:tensorflow:loss = 0.12782618, step = 19000 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.144\n",
      "INFO:tensorflow:loss = 0.12608036, step = 19100 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.843\n",
      "INFO:tensorflow:loss = 0.13776262, step = 19200 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.747\n",
      "INFO:tensorflow:loss = 0.1338419, step = 19300 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.418\n",
      "INFO:tensorflow:loss = 0.12410933, step = 19400 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.579\n",
      "INFO:tensorflow:loss = 0.12192101, step = 19500 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.614\n",
      "INFO:tensorflow:loss = 0.12820318, step = 19600 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.294\n",
      "INFO:tensorflow:loss = 0.1256167, step = 19700 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.799\n",
      "INFO:tensorflow:loss = 0.13337283, step = 19800 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.265\n",
      "INFO:tensorflow:loss = 0.122318804, step = 19900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.08\n",
      "INFO:tensorflow:loss = 0.121713504, step = 20000 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.719\n",
      "INFO:tensorflow:loss = 0.12432591, step = 20100 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.399\n",
      "INFO:tensorflow:loss = 0.12428103, step = 20200 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.599\n",
      "INFO:tensorflow:loss = 0.1251697, step = 20300 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.414\n",
      "INFO:tensorflow:loss = 0.12709491, step = 20400 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.621\n",
      "INFO:tensorflow:loss = 0.11272684, step = 20500 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.799\n",
      "INFO:tensorflow:loss = 0.12321839, step = 20600 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.013\n",
      "INFO:tensorflow:loss = 0.126182, step = 20700 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.733\n",
      "INFO:tensorflow:loss = 0.119268306, step = 20800 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.401\n",
      "INFO:tensorflow:loss = 0.120055705, step = 20900 (0.172 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 21000...\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 21000...\n",
      "INFO:tensorflow:Loss for final step: 0.11833821.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1c9d0de30a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=10000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-03-16T13:50:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt-21000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.87286s\n",
      "INFO:tensorflow:Finished evaluation at 2022-03-16-13:50:39\n",
      "INFO:tensorflow:Saving dict for global step 21000: accuracy = 0.96666664, average_loss = 0.13095672, global_step = 21000, loss = 0.13095672\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21000: C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt-21000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pedict :D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt-21000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (96.8%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (90.2%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (83.3%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also predict using user inputs :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Intern02\\AppData\\Local\\Temp\\tmpab0jzbw8\\model.ckpt-21000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Virginica\" (51.5%)\n"
     ]
    }
   ],
   "source": [
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "  valid = True\n",
    "  while valid: \n",
    "    val = input(feature + \": \")\n",
    "    if not val.isdigit(): valid = False\n",
    "\n",
    "  predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100 * probability))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "711553ad4eb01ae1e734b66fd636c846ef07e9e34bc336b1b859c2810f701e3c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
